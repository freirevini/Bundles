{
  "schema_version": "1.0",
  "id": "prompt-caching",
  "title": "Prompt Caching",
  "description": "\"Caching strategies for LLM prompts including Anthropic prompt caching, response caching, and CAG (Cache Augmented Generation) Use when: prompt caching, cache prompt, response cache, cag, cache augmented.\"",
  "version": "1.0.0",
  "entrypoint": "SKILL.md",
  "tags": [
    "llm",
    "rag"
  ],
  "tools": [],
  "priority": "normal",
  "compatibility": [
    "antigravity",
    "gemini-code-assist",
    "cursor",
    "claude-code"
  ],
  "author": "freirevini"
}